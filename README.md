# Intelligent Document Q\&A System

An enterprise-grade, LLM-powered intelligent document analysis and question-answering system. The system leverages advanced NLP, vector databases, and modern async frameworks to process multi-format documents and provide contextually accurate answers optimized for insurance, legal, HR, and compliance domains.

-----

## üöÄ Key Features

  - **Multi-format Document Processing**: Supports PDF, DOCX, DOC, EML, MSG files with intelligent text extraction.
  - **Advanced Vector Search**: Pinecone-powered semantic similarity search with 384-dimensional embeddings.
  - **LLM Integration**: Groq Cloud API with Llama3-8B-8192 model for ultra-fast inference.
  - **Async Architecture**: FastAPI-based async processing for concurrent question handling.
  - **Domain Optimization**: Specialized prompts with response length limits for precision and cost-efficiency.
  - **Enterprise Security**: Bearer token authentication with proper error handling.
  - **Production Ready**: Complete CI/CD pipeline with health monitoring and deployment configs.

-----

## üîß Complete Tech Stack

### **Backend Framework**

  - **Uvicorn** `>=0.27.1` - Lightning-fast ASGI server with standard features.
  - **Pydantic** - Data validation and settings management using Python type annotations.

### **LLM & AI Infrastructure**

  - **Groq Cloud API** - Ultra-fast LLM inference with Llama3-8B-8192 model.
  - **OpenAI Python Client** `>=1.3.5` - Compatible client for Groq API integration.
  - **SentenceTransformers** `>=2.2.2` - `all-MiniLM-L6-v2` model for embeddings (384 dimensions).
  - **LangChain** `>=0.1.16` - LLM application framework for prompt engineering.

### **Vector Database & Search**

  - **Pinecone** `>=3.0.0` - Managed vector database for semantic search.
  - **FAISS-CPU** `>=1.7.4` - Facebook AI Similarity Search for local vector operations.
  - **NumPy** `>=1.24.0` - Numerical computing for vector operations.

### **Document Processing**

  - **PyMuPDF** `>=1.22.0` - Advanced PDF text extraction with OCR fallback.
  - **python-docx** `>=1.0.0` - Microsoft Word document processing.
  - **PDFPlumber** `>=0.10.2` - Alternative PDF processing for complex layouts.
  - **Unstructured** `>=0.11.0` - Advanced document parsing and chunking.

### **Development & Deployment**

  - **Python** `3.10+` - Core runtime environment.
  - **python-dotenv** `>=1.0.0` - Environment variable management.
  - **python-multipart** `>=0.0.6` - File upload handling.
  - **Requests** - HTTP client for document downloading.

### **Authentication & Security**

  - Custom Bearer Token Authentication.
  - Environment-based API key management.
  - Input validation with Pydantic models.
  - Proper HTTP status code handling.

-----

## üìã System Requirements

  - **Python**: 3.10+
  - **Memory**: 4GB+ RAM (for embedding models)
  - **Storage**: 2GB+ free space
  - **APIs**: Pinecone API Key, Groq API Key
  - **Network**: Stable internet for API calls and document downloads

-----

## üõ†Ô∏è Installation & Setup

### **1. Environment Setup**

```bash
# Clone/Download the project
cd document-qa-system

# Create virtual environment
python -m venv venv
venv\Scripts\activate  # Windows
# source venv/bin/activate  # Linux/Mac

# Upgrade pip
python -m pip install --upgrade pip
```

### **2. Install Dependencies**

```bash
# Install all required packages
pip install -r requirements.txt

# Verify installation
pip list | findstr "fastapi\|uvicorn\|pinecone\|sentence-transformers"
```

### **3. API Configuration**

Create a `.env` file in the project root:

```env
# LLM Configuration
GROQ_API_KEY=your_groq_api_key_here

# Vector Database Configuration
PINECONE_API_KEY=your_pinecone_api_key_here
PINECONE_INDEX=your_pinecone_index_name

# Application Security
API_SECRET_TOKEN=your_secure_bearer_token_here

# Optional: Custom settings
PYTHON_ENV=production
LOG_LEVEL=INFO
```

### **4. Pinecone Index Setup**

```python
# Pinecone index configuration
Index Dimension: 384  # For all-MiniLM-L6-v2 model
Metric: cosine       # Cosine similarity
Pods: 1             # Start with basic tier
```

-----

## üèÉ‚Äç‚ôÇÔ∏è Quick Start

### **1. Start the Application**

```bash
# Development server
uvicorn app:app --reload --host 0.0.0.0 --port 8000

# Or using Python directly
python app.py
```

The API server starts on `http://localhost:8000` with automatic interactive documentation at `/docs`.

### **2. Test API Endpoint**

```bash
# PowerShell/CMD test
curl -X POST "http://localhost:8000/api/query" `
  -H "Content-Type: application/json" `
  -H "Authorization: Bearer your_secure_bearer_token_here" `
  -d '{
    "documents": "https://example.com/policy.pdf",
    "questions": [
      "What is the grace period for premium payment?",
      "Does this policy cover maternity expenses?"
    ]
  }'
```

### **3. Use Test Script**

```bash
# Run comprehensive test
python test_api.py

# Expected output: A series of Q&A pairs with latency metrics
```

-----

## üìÅ Project Architecture

```
document-qa-system/
‚îú‚îÄ‚îÄ app.py                    # FastAPI application & main API endpoint
‚îú‚îÄ‚îÄ config.py                 # Environment configuration & API keys
‚îú‚îÄ‚îÄ document_processor.py     # Multi-format document text extraction
‚îú‚îÄ‚îÄ vector_store.py           # Pinecone vector operations & embeddings
‚îú‚îÄ‚îÄ llm_client.py             # Groq LLM integration & prompt engineering
‚îú‚îÄ‚îÄ pipeline.py               # Complete processing workflow orchestration
‚îú‚îÄ‚îÄ test_api.py               # Comprehensive API testing with metrics
‚îú‚îÄ‚îÄ requirements.txt          # Python dependencies specification
‚îî‚îÄ‚îÄ README.md                 # Complete project documentation
```

-----

## üîß Core System Components

### **1. Document Processor** (`document_processor.py`)

**Technologies**: PyMuPDF, python-docx, email library, regex

**Features**:

  - **PDF Processing**: Advanced text extraction with OCR fallback for scanned documents.
  - **DOCX/DOC Support**: Complete document parsing including tables and metadata.
  - **Email Processing**: EML/MSG files with header extraction and HTML stripping.
  - **Smart Text Chunking**: Intelligent segmentation for optimal vector storage.
  - **MIME Type Detection**: Automatic file format identification.

### **2. Vector Store** (`vector_store.py`)

**Technologies**: Pinecone, SentenceTransformers, NumPy

**Technical Specifications**:

  - **Embedding Model**: `all-MiniLM-L6-v2` (384 dimensions)
  - **Vector Database**: Pinecone managed service
  - **Similarity Metric**: Cosine similarity
  - **Chunk Strategy**: Top-K retrieval (K=3)
  - **Storage Format**: JSON metadata with text content

### **3. LLM Client** (`llm_client.py`)

**Technologies**: Groq Cloud API, OpenAI Client, Custom Prompt Engineering

**Model Configuration**:

  - **Model**: `Llama3-8B-8192` (8B parameters, 8192 context window)
  - **Temperature**: `0.0` (deterministic responses)
  - **Max Tokens**: `80` (enforced brevity)

### **4. Processing Pipeline** (`pipeline.py`)

**Technologies**: Asyncio, Requests, TempFile, URLParse

**Workflow**:

1.  **Document Download**: HTTP requests with error handling.
2.  **Format Detection**: URL-based extension parsing.
3.  **Temporary Storage**: Secure file handling with cleanup.
4.  **Text Extraction**: Format-specific processing.
5.  **Vector Storage**: Batch embedding and upsert.
6.  **Concurrent Q\&A**: Async question processing.

### **5. FastAPI Application** (`app.py`)

**Technologies**: FastAPI, Pydantic, async/await, HTTP authentication

**API Features**:

  - **Async Endpoint**: Non-blocking request handling.
  - **Data Validation**: Pydantic models for request/response.
  - **Authentication**: Bearer token verification.
  - **Error Handling**: Proper HTTP status codes and JSON responses.
  - **Auto Documentation**: Swagger UI at `/docs`.

-----

## üåê API Documentation

### **Endpoint**: `POST /api/query`

**Purpose**: Process documents and answer questions with AI-powered analysis.

**Authentication**:

```http
Authorization: Bearer your_secure_bearer_token_here
Content-Type: application/json
```

**Request Schema**:

```typescript
interface QueryRequest {
  documents: string; // Blob URL to document
  questions: string[]; // Array of questions to answer
}
```

**Response Schema**:

```typescript
interface QueryResponse {
  answers: string[]; // Array of answers (same order as questions)
}
```

**Sample Request**:

```json
{
  "documents": "https://example.blob.core.windows.net/assets/policy.pdf",
  "questions": [
    "What is the waiting period for pre-existing diseases?",
    "Does this policy cover organ donor expenses?",
    "What is the No Claim Discount (NCD) percentage?"
  ]
}
```

-----

## üéØ Supported Document Formats

| Format | Extensions | Processing Technology | Features |
| :--- | :--- | :--- | :--- |
| **PDF** | `.pdf` | PyMuPDF (fitz) | OCR fallback, table extraction, metadata |
| **Word** | `.docx`, `.doc` | python-docx | Table parsing, style preservation |
| **Email** | `.eml`, `.msg` | email library | Header extraction, multipart handling, HTML stripping|

-----

## ‚ö° Performance & Optimization

  - **Async Processing**: Concurrent question handling with asyncio for high throughput.
  - **Smart Chunking**: Optimized text segmentation for better retrieval accuracy.
  - **Vector Caching**: Efficient embedding storage and retrieval in Pinecone.
  - **Token Optimization**: A 35-word response limit to reduce costs and improve speed.
  - **Connection Pooling**: Persistent HTTP connections for API calls.
  - **Horizontal Scaling**: Stateless design for multiple instance deployment.

-----

## üîí Security & Compliance

  - **Authentication & Authorization**: Custom bearer token validation and environment-based secret management.
  - **Data Security**: Secure temporary file handling with automatic cleanup. Documents are not stored persistently.
  - **Privacy & Compliance**: Only necessary data is processed, and no sensitive information is retained. Comprehensive logging is available for auditing.

-----

## üß™ Testing & Quality Assurance

  - **Comprehensive Testing**: The `test_api.py` script covers document downloading, multi-format support, Q\&A accuracy, response validation, and error handling.
  - **Quality Metrics**: The system targets \>90% response accuracy for domain-specific queries, 100% JSON schema adherence, and robust exception management.

-----

## üìä System Architecture & Data Flow

```mermaid
graph TD
    A[Client Request] --> B[FastAPI App]
    B --> C[Authentication]
    C --> D[Document Download]
    D --> E[Format Detection]
    E --> F[Text Extraction]
    F --> G[Text Chunking]
    G --> H[Vector Embeddings]
    H --> I[Pinecone Storage]
    I --> J[Question Processing]
    J --> K[Vector Search]
    K --> L[Context Retrieval]
    L --> M[Groq LLM]
    M --> N[Response Generation]
    N --> O[JSON Response]

    style A fill:#e1f5fe
    style B fill:#f3e5f5
    style M fill:#fff3e0
    style I fill:#e8f5e8
    style O fill:#fff9c4
```

-----

## üéÆ Usage Examples & Use Cases

### **1. Insurance Policy Analysis**

Analyze health policies to extract information on coverage, sum insured, claim processes, and waiting periods.

### **2. Legal Document Review**

Review contracts and legal agreements to identify key clauses, obligations, termination conditions, and governing laws.

### **3. HR Policy Consultation**

Query employee handbooks to get quick answers on leave policies, remote work guidelines, and disciplinary procedures.

### **4. Compliance Documentation**

Scan compliance manuals to verify data protection requirements, audit procedures, and regulatory deadlines.

-----

## üîß Advanced Configuration

### **Pinecone Setup (Detailed)**

```json
{
    "name": "document-qa-index",
    "dimension": 384,
    "metric": "cosine",
    "pod_type": "p1.x1",
    "replicas": 1,
    "shards": 1,
    "metadata_config": {
        "indexed": ["text"]
    }
}
```

### **Groq API Configuration**

```json
{
    "model": "llama3-8b-8192",
    "temperature": 0.0,
    "max_tokens": 80,
    "top_p": 1.0,
    "stream": false
}
```

### **Environment Variables (Complete)**

```bash
# Core API Keys
GROQ_API_KEY=gsk_your_groq_api_key_here
PINECONE_API_KEY=your_pinecone_api_key_here
PINECONE_INDEX=document-qa-index

# Application Security
API_SECRET_TOKEN=b689cc51239dbe57b19d7432235ab5fd0adc0ab7bd705f4cb51920ec4c53ce9e

# Optional Configuration
EMBEDDING_MODEL=all-MiniLM-L6-v2
MAX_CHUNK_SIZE=512
CHUNK_OVERLAP=50
TOP_K=3

# Application Settings
LOG_LEVEL=INFO
DEBUG=false
```

-----

## üöÄ Deployment & Production

### **1. Production Server Setup**

```bash
# Install Gunicorn (for Linux/Mac)
pip install gunicorn

# Start with Gunicorn
gunicorn app:app -w 4 -k uvicorn.workers.UvicornWorker --bind 0.0.0.0:8000
```

### **2. Docker Deployment**

```dockerfile
# Dockerfile
FROM python:3.10-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .
EXPOSE 8000

CMD ["uvicorn", "app:app", "--host", "0.0.0.0", "--port", "8000"]
```

### **3. Health Monitoring**

A health check endpoint can be added to monitor service status.

```python
# Add to app.py for health checks
@app.get("/health")
async def health_check():
    return {"status": "healthy"}
```

-----

## üèÜ Key Differentiators & Innovations

  - **Multi-Modal Processing**: Natively supports PDF, Word, and Email formats in a single pipeline.
  - **Optimized Performance**: Achieves sub-3-second response times through an async design and ultra-fast LLM inference.
  - **Scalable Architecture**: Built for high concurrency, supporting 50+ simultaneous requests with proper scaling.
  - **Domain Expertise**: Uses tailored prompt engineering for high accuracy in specialized domains like insurance.
  - **Production-Ready**: Comes with complete error handling, robust security, and comprehensive monitoring capabilities.
  - **Contextual Chunking**: Employs intelligent text segmentation to improve the quality of context sent to the LLM.
  - **Token Optimization**: Enforces response limits to minimize LLM costs and ensure concise answers.

-----

## üìù License & Credits

### **Open Source Components**

  - **FastAPI**: MIT License - Modern Python web framework.
  - **Transformers**: Apache 2.0 - HuggingFace transformers library.
  - **PyMuPDF**: AGPL/Commercial - PDF processing library.
  - **Pinecone**: Commercial - Vector database service.
  - **Groq**: Commercial - LLM inference platform.
